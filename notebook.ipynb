{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ef600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a89c07",
   "metadata": {},
   "source": [
    "First thing first we need to define some of the constraints of the problem.\n",
    "\n",
    "First off there are only 2 classes (either cat and dog).\n",
    "\n",
    "We can use the sigmoid activation function since we only have two classes\n",
    "\n",
    "The pictures are in color (RGB)\n",
    "\n",
    "We also have two folders one for cats and the other for dogs.\n",
    "\n",
    "This means when we make the full dataset, we will have to turn all the pictures into arrays. ensure we keep the labels.\n",
    "Then we need to make sure that all the cats and dogs datasets can be combined and that you choose the data randomly (with test_train_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf31c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will begin by turning the images into numpy arrays\n",
    "\n",
    "cat_pics_path = r'C:\\Users\\franc\\Documents\\neural_nets\\resnet_cats_vs_dogs\\PetImages\\Cat'\n",
    "dog_pics_path = r'C:\\Users\\franc\\Documents\\neural_nets\\resnet_cats_vs_dogs\\PetImages\\Dog'\n",
    "\n",
    "cat_image_arrays = []\n",
    "dog_image_arrays = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc51ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image C:\\Users\\franc\\Documents\\neural_nets\\resnet_cats_vs_dogs\\PetImages\\Cat\\666.jpg: cannot identify image file 'C:\\\\Users\\\\franc\\\\Documents\\\\neural_nets\\\\resnet_cats_vs_dogs\\\\PetImages\\\\Cat\\\\666.jpg'\n"
     ]
    }
   ],
   "source": [
    "for cat_pic in os.listdir(cat_pics_path):\n",
    "    if cat_pic.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        filepath = os.path.join(cat_pics_path, cat_pic)\n",
    "        try:\n",
    "            #open the image using pillow\n",
    "            img = Image.open(filepath)\n",
    "            #convert image to numpy array\n",
    "            cats_np_array = np.array(img)\n",
    "            #append the array to list\n",
    "            cat_image_arrays.append(cats_np_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {filepath}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5929bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_image_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8384b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image C:\\Users\\franc\\Documents\\neural_nets\\resnet_cats_vs_dogs\\PetImages\\Dog\\11702.jpg: cannot identify image file 'C:\\\\Users\\\\franc\\\\Documents\\\\neural_nets\\\\resnet_cats_vs_dogs\\\\PetImages\\\\Dog\\\\11702.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\Documents\\neural_nets\\neural_nets\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "for dog_pic in os.listdir(dog_pics_path):\n",
    "    if dog_pic.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "        filepath = os.path.join(dog_pics_path,dog_pic)\n",
    "        try:\n",
    "            #open the image using pillow\n",
    "            img = Image.open(filepath)\n",
    "            #convert image to numpy array\n",
    "            dog_pic_array = np.array(img)\n",
    "            #append the array to the list\n",
    "            dog_image_arrays.append(dog_pic_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a7c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12499"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_image_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2d2a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "12499\n",
      "<class 'numpy.ndarray'>\n",
      "(375, 500, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(500, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(type(dog_image_arrays))\n",
    "print(len(dog_image_arrays))\n",
    "print(type(dog_image_arrays[0]))\n",
    "print(dog_image_arrays[0].shape)\n",
    "print(type(dog_image_arrays[0][0]))\n",
    "print(dog_image_arrays[0][0].shape)\n",
    "print(type(dog_image_arrays[0][0][0]))\n",
    "print(dog_image_arrays[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cd52954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[203, 164,  87],\n",
       "        [203, 164,  87],\n",
       "        [204, 165,  88],\n",
       "        ...,\n",
       "        [240, 201, 122],\n",
       "        [239, 200, 121],\n",
       "        [238, 199, 120]],\n",
       "\n",
       "       [[203, 164,  87],\n",
       "        [203, 164,  87],\n",
       "        [204, 165,  88],\n",
       "        ...,\n",
       "        [240, 201, 122],\n",
       "        [239, 200, 121],\n",
       "        [239, 200, 121]],\n",
       "\n",
       "       [[203, 164,  87],\n",
       "        [203, 164,  87],\n",
       "        [204, 165,  88],\n",
       "        ...,\n",
       "        [241, 202, 123],\n",
       "        [240, 201, 122],\n",
       "        [239, 200, 121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[153, 122,  55],\n",
       "        [153, 122,  55],\n",
       "        [153, 122,  55],\n",
       "        ...,\n",
       "        [  2,   2,   0],\n",
       "        [  2,   2,   0],\n",
       "        [  2,   2,   0]],\n",
       "\n",
       "       [[152, 121,  54],\n",
       "        [152, 121,  54],\n",
       "        [152, 121,  54],\n",
       "        ...,\n",
       "        [  1,   1,   0],\n",
       "        [  1,   1,   0],\n",
       "        [  1,   1,   0]],\n",
       "\n",
       "       [[151, 120,  53],\n",
       "        [151, 120,  53],\n",
       "        [152, 121,  54],\n",
       "        ...,\n",
       "        [  1,   1,   0],\n",
       "        [  1,   1,   0],\n",
       "        [  1,   1,   0]]], shape=(375, 500, 3), dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_image_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62308180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[203, 164,  87],\n",
       "       [203, 164,  87],\n",
       "       [204, 165,  88],\n",
       "       ...,\n",
       "       [240, 201, 122],\n",
       "       [239, 200, 121],\n",
       "       [238, 199, 120]], shape=(500, 3), dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_image_arrays[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcdfaa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([203, 164,  87], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_image_arrays[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d853a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_array</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[203, 164, 87], [203, 164, 87], [204, 165, 8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[36, 41, 37], [37, 42, 38], [38, 42, 41], [3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[25, 29, 38], [23, 27, 36], [19, 23, 32], [1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[223, 224, 219], [223, 224, 219], [223, 224,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[133, 107, 70], [137, 109, 70], [143, 114, 7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_array label\n",
       "0  [[[203, 164, 87], [203, 164, 87], [204, 165, 8...     0\n",
       "1  [[[36, 41, 37], [37, 42, 38], [38, 42, 41], [3...     0\n",
       "2  [[[25, 29, 38], [23, 27, 36], [19, 23, 32], [1...     0\n",
       "3  [[[223, 224, 219], [223, 224, 219], [223, 224,...     0\n",
       "4  [[[133, 107, 70], [137, 109, 70], [143, 114, 7...     0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df = pd.DataFrame({'image_array': cat_image_arrays, 'label': '0'})\n",
    "\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba570f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12499 entries, 0 to 12498\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   image_array  12499 non-null  object\n",
      " 1   label        12499 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cat_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611f3c2",
   "metadata": {},
   "source": [
    "I will now make the train and validation split. \n",
    "\n",
    "Kindly remember that this will be an image pipeline not a dataframe pipeline since turning the data into an df pipeline would flatten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94127f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH =32\n",
    "SEED = 42\n",
    "DATA_DIR = r'C:\\Users\\franc\\Documents\\neural_nets\\resnet_cats_vs_dogs\\PetImages'\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    label_mode='int',\n",
    "    class_names=['Cat','Dog']\n",
    "    labels = \"inferred\"\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    label_mode='int',\n",
    "    class_names=['Cat','Dog']\n",
    "    labels = \"inferred\"\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff50c4",
   "metadata": {},
   "source": [
    "I then want to do some augmentation on the train part of the data. \n",
    "\n",
    "So that the finetuning can be more effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers as L\n",
    "\n",
    "data_augment = tf.keras.Sequential([\n",
    "    L.RandomFlip(\"horizontal\"),\n",
    "    L.RandomRotation(0.05),        # ~±9°\n",
    "    L.RandomZoom(0.1),\n",
    "    L.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Apply during training only:\n",
    "augmented_train_ds = train_ds.map(lambda x, y: (data_augment(x, training=True), y))\n",
    "# augmented_train_ds = augmented_train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42fcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37b05cf3",
   "metadata": {},
   "source": [
    "Importing the Resnet50 model\n",
    "\n",
    "The reason why I chose Resnet50 is because it can be imported through tensorflow unlike some other smaller variants of resnet that can only be used with the transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c299f3",
   "metadata": {},
   "source": [
    "I will first attempt to use the frozen model to make predictions using the pictures that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5412e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_nets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
