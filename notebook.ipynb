{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ef600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a89c07",
   "metadata": {},
   "source": [
    "First thing first we need to define some of the constraints of the problem.\n",
    "\n",
    "First off there are only 2 classes (either cat and dog).\n",
    "\n",
    "We can use the sigmoid activation function since we only have two classes\n",
    "\n",
    "The pictures are in color (RGB)\n",
    "\n",
    "We also have two folders one for cats and the other for dogs.\n",
    "\n",
    "This means when we make the full dataset, we will have to turn all the pictures into arrays. ensure we keep the labels.\n",
    "Then we need to make sure that all the cats and dogs datasets can be combined and that you choose the data randomly (with test_train_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = 'C:/Users/franc/Documents/neural_nets/resnet_cats_vs_dogs/PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b09077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_file_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size = 64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    image_size=(224,224)\n",
    ")\n",
    "\n",
    "validation_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_file_path,\n",
    "    labels='inferred',\n",
    "    label_mode = 'categorical',\n",
    "    batch_size = 64,\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'validation',\n",
    "    image_size = (224,224)\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611f3c2",
   "metadata": {},
   "source": [
    "I will now make the train and validation split. \n",
    "\n",
    "Kindly remember that this will be an image pipeline not a dataframe pipeline since turning the data into an df pipeline would flatten the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e28416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18282ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=autotune)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=autotune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff50c4",
   "metadata": {},
   "source": [
    "I then want to do some augmentation on the train part of the data. \n",
    "\n",
    "So that the finetuning can be more effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment = keras.Sequential([\n",
    "    layers.RandomRotation(0.05),        # ~±9°\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Apply during training only:\n",
    "# augmented_train_ds = train_dataset.map(lambda x, y: (data_augment(x, training=True), y))\n",
    "# augmented_train_ds = augmented_train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a42fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply during training only:\n",
    "augmented_train_ds = train_dataset.map(lambda x,y:(data_augment(x,training=True),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b05cf3",
   "metadata": {},
   "source": [
    "Importing the Resnet50 model\n",
    "\n",
    "The reason why I chose Resnet50 is because it can be imported through tensorflow unlike some other smaller variants of resnet that can only be used with the transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47fbd3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c299f3",
   "metadata": {},
   "source": [
    "I will first attempt to use the frozen model to make predictions using the pictures that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5412e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_nets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
